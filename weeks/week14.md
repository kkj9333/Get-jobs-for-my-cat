# Day14 MimicNet: Fast Performance Estimates for Data Center Networks with Machine Learning

## 前提摘要
本文介绍了MimicNet，一种用于快速获取数据中心网络性能估计的方法。MimicNet提供了一个包级模拟的抽象，利用冗余性和机器学习的最新进展，快速准确地近似不直接可见的网络部分。
与常规模拟相比，MimicNet可以为拥有数千台服务器的数据中心提供超过两个数量级的加速。即使在这种规模下，MimicNet对FCT、吞吐量和RTT的估计结果与真实结果相差不到5%。 
MimicNet使用了深度学习模型和流近似技术，可以将非可观测部分的行为快速逼近，并组成一个可扩展的生成模型，达到与全尺度模拟相同甚至更好的准确性。
作者在数据中心网络的预生产性能评估方面提供了一个快速估计的解决方案，克服了今天网络规模的挑战。

## 研究背景
数据中心网络是连接网络中大型计算机集群的基础设施，处理大量的数据和服务，如云计算、视频流媒体、在线游戏等。而对于数据中心网络的性能评估是很重要的，因为它直接影响到用户的体验和服务的质量。然而，对于大规模、复杂的数据中心网络进行精确的性能评估需要大量的计算资源和时间。因此，研究如何快速准确地估计数据中心网络性能是一个重要的课题。

## 重要专有名词及概念
#### 数据中心	
一个设备集群，用于远程处理、存储和分发大量数据。
#### 规模评估	
测量和分析新技术或战略的效果和成本。
#### 测试平台	
再现真实环境和专门测试新技术或战略的环境。
#### 数据中心副本	
一个完整的、准确复制的数据中心。
#### 模拟
在计算机上使用一个模型来预测或评估真实世界中的现象或情况。
#### MimicNet
一种用于快速获得大型数据中心网络准确性能估计的系统。
#### 包级别模拟
模拟计算机网络中数据包的传输和处理过程。
#### 冗余
处理中发生错误时，不会丢失数据的备份系统。
#### 机器学习
让计算机自动学习，从而识别、分类和预测模式。
#### 吞吐量
网络中的数据处理速度。
#### RTT（Round-Trip Time）
往返时延，指从数据包发送到确认接收的时间，通常用于考虑网络通信的延迟时间。
#### 尾端FCT
定义为完成传输的最后一个字节和请求发出时间差的时间。
#### 包级模拟
包级模拟是在计算机网络中单个数据包的层面上进行模拟，即对于每个经过网络的数据包都会进行详细的模拟和跟踪。可详细的分析和评估单个数据包的行为和特征。包级模拟可以实现在任意网络设计下的灵活性和评估方面的丰富性，十分具有实用性
#### 流级模拟
流级模拟则是在更高层的抽象上进行模拟，它将数据包看作是一组有序的数据流，通过对整个流进行建模和跟踪来评估网络的性能。相对于包级模拟，流级模拟可以更快速地模拟流。
### 流完成时间（Flow Completion Time，FCT）
是指从一个流的第一个数据包从源节点传输到网络中的最后一个数据包到达目标节点所需的时间。FCT是衡量网络性能的一个重要指标，直接关系到数据传输的质量和用户的体验。通常，FCT越短表示网络性能越好。
### FatTree拓扑
Fat-tree使用了多个小规模、低成本的交换机替代了原来核心层、汇聚层昂贵的、高密度端口的交换机。相同点是，也都是三层架构，核心层、汇聚层、接入层。
- k叉树，即假设交换机的端口数量为k（图3中k=4）；
- 核心交换机数量为 (k/2)^2，pod的数量为k；
- 每个pod分为两层，每层k/2个交换机，上层称为汇聚层，下层称为接入层（也称Edge Layer）；
- 汇聚层k/2的端口连接k/2的核心交换机，剩下的端口连接接入层的交换机；
- 接入层同上，一半的端口连接上一层，一半的端口连接下面的主机。
![image](https://user-images.githubusercontent.com/51207072/229326917-5831ecbe-9519-415f-9be8-c2ea158e1cd4.png)
### 机架（rack）
机架是一种用于存放服务器和其他计算设备的结构，它们通常按照一定的顺序排列在数据中心或集群中。
### 目标机架（destination rack）
目标机架（destination rack）通常指数据中心或集群中的一个特定机架，它是数据传输或通信的目的地。
### 尾部行为（tail behavior）
尾部行为是指统计分布在极端值区域的性质，它影响了随机变量之和的收敛性和稳定性。
在延迟中，表现为尾延迟（Tail Latency）。总会有少量响应的延迟高于均值，即尾延迟。对于大规模分布式系统来说，尾延迟的影响尤其严重，例如大规模搜索引擎，单个请求可能就会发送到上万台服务器，系统不得不等待尾延迟响应返回之后才能返回给用户。
### 上下路由（strict up-down routing）
上下路由是一种用于多层次网络拓扑结构中的路由策略。<u>它要求数据包在从源节点到达目标节点的过程中，必须先沿着网络层次结构向上移动，直到到达最高层，然后再沿着网络层次结构向下移动，直到到达目标节点。</u>
这种路由策略可以防止数据包在网络中出现环路，从而避免了可能导致网络拥塞和性能下降的问题。严格的上下路由通常用于具有明确层次结构的网络拓扑结构中，例如fat-tree拓扑结构。
总之，严格的上下路由是一种用于多层次网络拓扑结构中的路由策略，它要求数据包在从源节点到达目标节点的过程中，必须先沿着网络层次结构向上移动，然后再沿着网络层次结构向下移动。
### 集群-本地流量
集群本地流量（cluster-local traffic）指的是在同一集群内部的节点之间传输的数据流量。集群是指一组紧密连接在一起的计算机，它们共同协作完成特定的任务。集群内部的节点通常通过高速网络连接在一起，以便快速地传输数据。
集群本地流量通常指的是在集群内部节点之间传输的数据流量，而不包括与外部节点之间的数据流量。**这种流量通常用于支持集群内部的协作计算和数据处理任务**。
总之，集群本地流量指的是在同一集群内部的节点之间传输的数据流量。它用于支持集群内部的协作计算和数据处理任务。
### 扇入拥塞
扇入拥塞（fan-in congestion）是指**在计算机网络中，当多个数据流同时传输到同一个目标节点时，由于目标节点的处理能力有限，导致数据包排队等待处理，从而造成拥塞的情况**。
扇入拥塞通常发生在网络中的瓶颈节点，例如交换机或路由器。当这些节点需要同时处理大量传入的数据流时，它们的处理能力可能会饱和，导致数据包排队等待处理。这种情况会降低网络的性能，增加数据包的传输延迟。
为了避免扇入拥塞，网络管理员通常会采取一些措施来平衡网络流量，例如使用流量整形技术来控制数据流的传输速率，或者使用负载均衡技术来将流量分散到多个路径上。
### 贝叶斯优化
贝叶斯优化是一种全局优化算法，用于找到目标函数的最大值或最小值。该算法通过不断地添加样本点来更新目标函数的后验分布，直到后验分布基本贴合于真实分布。贝叶斯优化用于机器学习调参，可以对不可微分、不连续且计算耗时的函数进行优化。该算法在内部维护目标函数的高斯过程模型，并使用目标函数计算来训练此模型。  
详情请见[一文读懂贝叶斯优化](https://zhuanlan.zhihu.com/p/150555551)
和[深入理解贝叶斯](https://www.cnblogs.com/marsggbo/p/9866764.html).
### Wasserstein指标
Wasserstein指标是一种用于度量两个概率分布之间差异的方法，它满足“距离”所需要的三个条件，因此被称为“距离”1。Wasserstein指标也被称为Wasserstein距离。  
Wasserstein指标可以作为两个概率分布的距离衡量指标，其定义如下：是概率分布 的距离，它是两个在同一空间上（即维度相同）的随机变量x，y之差的范数均值的下确界2。在不同 分布下，求出W的下界，即是Wasserstein 距离。

## 设计目标
1. 提供快速准确的数据中心网络性能估计。利用深度学习模型和流逼近技术，快速准确地近似不直接可见的网络部分。
2. 保持估计结果的准确性，以便更好地应用于预生产性能评估等方面。
3. 可调性，用户应该能够定义自己的准确性度量，并将这种准确性与改进的结果时间进行权衡。
4. 能够适应不同的网络拓扑结构和网络流量负载，并且具有较好的扩展性和灵活性。
5. ~~克服数据中心网络规模的挑战，为拥有数千台服务器的数据中心提供超过两个数量级的加速。~~
## 概观
MimicNet使用深度学习模型和流逼近技术相结合的方法来近似整个数据中心网络。
<br>具体而言，MimicNet首先使用深度学习模型来学习数据中心网络中各种网络元素之间的复杂关系，包括物理设备、拓扑结构、传输协议等等。该模型可以预测网络中各类统计特性的值，如流的大小、持续时间和传输时间等。
<br>然后，MimicNet使用流逼近技术逼近数据中心网络中不可观测的部分行为。针对数据流的大小、源目的地址等维度，MimicNet进行拟合，最终形成一个可扩展的生成模型。这个模型可以对不可见的网络部分进行快速逼近，从而实现对整个数据中心网络的近似。
### Mimic
MimicNet在单个数据中心集群的粒度上构建和组成模型：Mimic。从外部来看，Mimic类似于规则的集群。它们的主机会初始化连接并与外部世界交换数据，而它们的网络就会根据内部队列和集群的交换机的逻辑来丢弃（drop）、延迟和修改这些流量，然而，Mimic的不同之处在于，它们能够预测排队和协议操作的影响，而无需模拟或与其他Mimic交互——只与可观察的集群（cluster）交互。<br>
#### **MimicNet实质是用于数据中心网络的基于ML的数据包模拟框架。**
出于为了产生其（大规模模拟）特征的结果，它在每个模拟中包含的两种类型的帮助下实现了上述目标： 
- [基于深度学习的内部模型](week14.md#内部模型)，学习交换机、链接、队列和集群内交叉流量的行为；（intra-cluster近似）
- [基于流的馈线模型](week14.md#反馈模型)，近似于集群间的交叉行为。（inter-cluster近似）

后者由数据中心的大小进行参数化。这些模型一起取一系列可观测的数据包及其到达时间，并输出集群的预测效果：
1. 数据包**是否**由于队列管理策略而丢弃
2. 如果没被丢弃，数据包**何时**离开（出口）Mimic
3. 基于路由表，数据包从**哪里**离开（出口）
4. 在途径Mimic后的数据包的**内容**是怎样了，包括诸如TTL和ECN等修改
#### 工作流
MimicNet（如图）的使用从完整模拟的一小个子集开始：只有两个用户定义的集群相互通信。这种全保真度、小规模的模拟用于生成训练和测试集，用于上述模型的监督学习。增强这个训练阶段是一个可选的超参数调优阶段（4），在这个阶段中，MimicNet探索了各种建模选项（Model Training->Model Testing->Model Training...）。<br>
![image](https://user-images.githubusercontent.com/51207072/229673284-a9df1ed1-b92b-404e-bd26-055bd06c7657.png)<br>

对于数据生成（1）和大规模模拟（5），MimicNet都使用OMNeT++作为模拟基底。 
（1）作为第一步，由一个集群（cluster）去收集训练数据；  
（2）然后将其用于模型（Mimic）的训练（以模拟和代替另一个集群（cluster）作为根本目标）；  
（3）接下来进行模型测试，测试训练模型的准确性，并且（4）有一个可选的超参数调优阶段来调整超参数；  
（5）最终将所有的集群（cluster）用训练的Mimics替换（仅保留一个真实的集群（cluster），这个cluser就是 observable cluster），并构成最终的大规模模拟。
### 性能分析
![image](https://user-images.githubusercontent.com/51207072/229676245-6cdad7bf-1b35-48c2-8072-d1a5b25f19fc.png)<br>
如上图所示是Mimic以及通过它的数据包的类型。在高级别上，有两种类型：
- （1）与可观测集群（Cluster）交互的流量（Mimic-Real）
- （2）与可观测集群不交互的流量（Mimic-Mimic），这部分又可分为inter-Mimic{6}和intra-Mimic{5}。如图红线表示，请注意这部分流量是用论文的模型近似的，{6}用的[Feeder Model](week14.md#反馈模型)，{5}用的[Internal Model](week14.md#内部模型)。<br>
假设我们的模拟是N个集群（N>=2），T代表在**数据中心的全模拟**中发送的数据包的数量，𝑝是离开集群与停留在集群内（inter-to-intra）的流量的比率（集群间到集群内）(0<𝑝<1)那么在完整模拟中离开单个集群的流量数量就是 $T𝑝 \over N$。  
PS:我的理解是𝑝就是蓝色部分的流量比上红色部分的流量的比例，而T代表的**数据中心全模拟**时的流量的数据包数量，现在MimicNet替换了其中N-1个集群为Mimic集群（基于ML模拟的）， 所以在MimicNet中的流量数据包有 $T(1+𝑝) \over N$，相比之前减少 $N \over 1+𝑝$ ，请注意0<𝑝<1。   
因为Mimic仅与单个可观测群进行通信，而不是相互通信，所以在近似模拟中离开Mimic的数据包数量如下（按照论文意思，N-集群具有𝑁-1个Mimice集群和单一个可观察集群）:
$$T𝑝 \over N(N-1)$$
因此，在MimicNet模拟中生成的数据包总数（在可观测集群中生成的所有流量的组合和N-1个Mimics）：
$$\frac{T}{N}+\frac{(N-1)T𝑝}{N(N-1)}=\frac{T+T𝑝}{N}$$
论文在数据中心网络架构、数据包的大小和频率、拥塞发生时段（fan-in only）、主机内隔离进行了限制和假设，因此，MimicNet作为迈向大规模网络预测的第一步，并不适合评估所有的数据中心的架构或配置。
## 内部模型
模拟模型由两种类型的模型组成。第一种类型是建模内部集群行为，它的目标如下：
1. 对于外部通信（包括 Mimic-Real and Mimic-Mimic），能够预测集群（cluster）的网络将如何影响包：是否下降、延迟、下一跳以及任何包修改。
2. 对于内部通信（在同一Mimic中的主机之间），移除并将其效果烘托到上述预测中。换句话说，在推理过程中，模型应该解释内部流量的可观察影响而不是明确地看到它。
请注意，并不是所有可观察的效应都需要学习（比如如果结果可以使用一个简单的、确定性的函数来计算）；而对于其他模型-需要将模型扩展到未观察到的配置，这给可泛化学习带来了一个独特的挑战。MimicNet仔细地管理了训练数据、特征集和模型，确保生成的模型与规模无关。
### 小规模观测
MimicNet首先运行一个小规模但全保真度的模拟（simulation）来收集训练/测试数据。
用户首先以一种可以插入基于C++的OMNeT++模拟框架的格式提供他们的主机和交换机实现，MimicNet对通过一组核心交换机连接的两个集群进行全保真模拟，并指定其中一个进行建模，记录所有进入和离开集群的数据包。在FatTree网络中，这相当于监测面向核心交换机和主机的接口，**在这两个连接之间是队列和路由器的机制（the mechanics of the queues and routers）**，Mimic内部模型学习和近似队列和路由的机制。
#### 预处理
MimicNet获取数据包转储，并使用数据包中的标识符（例如，序列号）对输入和离开网络的数据包进行**匹配**。检查**匹配**项有助于确定它在集群中花费的时间长度和数据更改。丢失（loss）和多播（muticast）无法进行一对一**匹配**，丢失可以被检测为一个进入集群但永远不会离开的数据包。多播广播必须由框架进行跟踪。**两者都可以建模**。
### 建模目标
MimicNet将集群（cluster）的效应建模为机器学习任务。对于每个外部流量的包i：
#### 延迟回归
我们将𝑖在集群网络中花费的时间建模为一个有界连续随机变量，并设置目标以最小化真实延迟和预测之间的平均绝对误差（以MAE）：  
$$min\sum |y_i^l-{\hat{y}}_i^l|$$

在这里$y_i^l$当数据包被丢弃时表示$𝐿_{max}+\epsilon$，否则表示$𝐿_{at}\in[L_{min},L_{max}]$。${\hat{y}}_i^l$表示预测延迟。MimicNet在训练延迟模型中使用了离散化方法来提高准确性：  
$$f(y^l) ={{y^l-L_{min}}\over{L_{max}-L_{min}}}\times D $$
𝐷是控制离散化程度的超参数。通过改变𝐷，我们可以权衡建模的容易性和离散化的恢复精度。
#### 丢弃（drop）和数据包修改分类
对于大多数其他任务，分类更适合。例如，对一个数据包下降的预测有两种可能的结果，其目标是最小化二进制交叉熵（BCE）：  
 ![image](https://user-images.githubusercontent.com/51207072/230309277-1bac63ce-4102-4ab2-90ff-b2296050161c.png)  
其中$y_i^d$当数据包i被丢弃时表示1，否则表示0，${\hat{y}}_i^d\in[0,1]$表示数据包i被丢弃的预测概率。数据包修改（比如ECN位预测）有类似这样的目标函数。  
于是在论文中，回归和分类任务都与一个统一的损失函数一起建模。

### 可伸缩特征选择
特征选择在任何机器学习里都是非常重要的，MimicNet接下来必须选择能够很好地映射到目标预测的特征。此外，MimicNet引入了一个额外的约束——这些特性是可伸缩的。
<br>
**可伸缩特性**是指无论模拟中的集群数量如何，都仍然有意义的特性。考虑一个从核心交换机进入Mimic集群（cluster）并面向集群（cluster）内的一个主机的数据包。
对于一个拥有R个机架的集群，[目标机架](week14.md#目标机架destination-rack)的本地索引（[0,R)）是一个可伸缩的特征，因为添加更多的集群不会影响特性的值、范围或语义。反例：源服务器IP将不是一个可伸缩的特性，只要两个集群时，它确实可以唯一标识一个数据包，但是随着集群的添加，未见过的IP就成为了新的数据。
<br>
#### 可伸缩特性表
下表列出了数据中心网络中的可伸缩特性，适用于进入和出口数据包。其他未列出的可伸缩特性包括<u>优先级位、数据包类型和ECN标记</u>。
![image](https://user-images.githubusercontent.com/51207072/230323105-8979910d-e645-4c38-8816-c0f37d24c6d7.png)
<br>
MimicNet对捕获的特征进行两次转换：
1. 将数据包的前四个特征独热编码，以删除设备间的任何隐式排序。
2. 离散两个时间相关的特征（如[建模目标中的参数D等](week14.md#建模目标)）。

<br>
至关重要的是，所有这些特性都可以仅使用数据包头、交换机路由表和模拟器本身来快速确定。

### DCN友好性损失函数（DCN-friendly Loss Functions）
由于本领域的几个特点之前的是不能直接用来当损失函数的，我们需要选择一个适当的训练损失函数：
类不平衡：即使在负载严重的网络中，像数据包下降和ECN标记这样的不良事件也相对很少发生。如下图所示使用不同损失函数的一秒钟测试集的真实值（Ground Truth）和LSTM预测的丢弃（drop）和非丢弃：

![使用不同损失函数的一秒钟测试集的真实值（Ground Truth）和LSTM预测丢弃。y轴是1表示丢弃，0表示不是。真实样本的丢弃率为0.3%，而采用BCE损失的预测丢弃率为0.01%。采用WBCE（Weighted BCE）的预测结果是更真实的根据权重决定的丢弃率（𝒘= 0.6： 0.14%；𝒘= 0.9： 0.49%）](https://user-images.githubusercontent.com/51207072/230365800-56f20631-bb22-4c16-9483-cee8337342c9.png)<br>
在一秒钟周期内的丢弃的示例跟踪，由于训练集中99.7%都是没有被丢弃的，这意味着一个损失模型即使它总是预测“没有丢弃”也可以获得很高的准确性。
（b）使用在上面相同的轨迹上使用BCE损失训练的LSTM举例说明了这种效果。它预测的丢弃速率几乎比真实的丢弃速率低一个数量级。为了解决这个类不平衡的实例，MimicNet采用了一种成本敏感的学习方法，采用了加权bce（WBCE）损失：
![image](https://user-images.githubusercontent.com/51207072/230372408-a4d02a1a-2324-4611-bba2-fe6edbf60a8c.png)<br>
𝑤是控制丢弃类上的权重的超参数。整个函数是对所有数据包的BCE值求和，并根据超参数w选择总体预测的丢弃和正常的熵所占比例（w主要与丢弃部分有关，为了增大丢弃部分的影响），来缓解数据集分布不平衡的问题。根据我们的经验，0.6.∼0.8是一个合理的范围，我们依赖于[可选超参数调优](week14.md#可选超参数调优)中的调优技术来为给定的网络配置和目标度量找到最佳的𝑤。
#### 延迟中的极端值（Outliers in latencies）
在延迟方面，一个类似的挑战是准确地学习[尾部行为](week14.md#尾部行为tail-behavior)。考虑如下图（a）所示的前一个跟踪中的延迟：
![image](https://user-images.githubusercontent.com/51207072/230366454-5449c221-45c0-4697-8430-283d82d1fe99.png)<br>
虽然大多数值都很低，但少数数据包在拥塞期间会产生非常大的延迟；这些异常值对于准确地建模网络非常重要，[MAE](week13.md#mae)作为一个损失函数未能捕捉到这些值的重要性（延迟预测如上图（b）所示。另外我们注意到，另一个常见的回归损失函数，[均方误差（MSE）](week13.md#mse)，有相反的问题——它将每个样本的损失平方，并产生倾向于高估异常值（过于看重异常值）的模型。
因此MimicNet使用了[Huber损失函数](week12.md#huber-loss)：
![image](https://user-images.githubusercontent.com/51207072/230379659-da4de100-f40d-4863-837b-e7ce6c7a81c3.png)<br>

其中，$\delta\in R^+$是一个超参数。本质上，Huber损失假设了一个重尾误差（ heavy-tailed error）分布，并使用了不同情况下的平方损失和绝对损失。上图（d）显示了使用Huber损失（$\delta$ = 1）训练的模型的结果。在这种特殊情况下，它将99%延迟的不准确性（以MAE测量）从13.2%降低到只有2.6%。
### 联合损失函数
为了在模型训练过程中结合上述损失函数，MimicNet对所有值进行归一化，并使用超参数对其进行加权。一般来说，<u>支持延迟优于其他指标的权重更可取</u>，因为回归是一个比分类更难的任务。
### 可泛化模型的选择
最后，通过特征和损失函数，MimicNet可以开始为用户的集群建模。<br>
该模型应该能够学习近似于**队列和接口的机制（the mechanics of the queues and interfaces）**，以及集群-本地（cluster-local）流量及其对网络条件的反应（例如，由于拥塞控制的结果）。模型有很多，但是一个合适的目标网络对于速度和精度的优化非常重要。
为此目的，MimicNet可以支持任何ML模型。然而，鉴于我们对通用性的渴望，它目前利用了一个特别有前途的模型类：LSTM。LSTM最近因其能够在没有明确的特征工程的情况下学习数据序列中复杂的底层关系而受到关注。
### 进出口分解（Ingress/egress decomposition）
为了简化所需的模型，提高训练效率，MimicNet分别建立了进出流量的模型。这种方法部分是由于MimicNet要求严格的[上下路由](week14.md#上下路由strict-up-down-routing)、[集群-本地流量](week14.md#集群-本地流量)的内在建模和[扇入拥塞](week14.md#扇入拥塞)的假设。<br>
虽然这个决定（分别建立进出流量模型）仍然存在一些不准确的地方（例如，共享缓冲区的影响）,但是实验结果表明，对于我们测试的所有架构，这个选择是另一个良好的速度/准确性权衡。<br>
egress Model判断远程主机发过来的包，首先判断是否需要丢弃，若不需要则预测要跳转的集群，通过核心交换机转发给对应的集群，
对于每个方向的流量，LSTM由一个输入层和一堆扁平的、一维的隐藏层组成。隐藏层的大小是$\#features \times \#packets$，#features是独热编码后的特征数，#packets是一次采样的数据包数量。
### 拥塞状态增强（Congestion state augmentation）
虽然理论上LSTM可以记忆长期模式，但是实际情况下往往被限制只能看一小段的，相比之下，Mimic所看到的流量可能表现出数十万个数据包的自相似性。这里的问题实际上引出了一个多尺度模型的性质。
正因为如此，我们用一种网络域知识来增强LSTM模型：对每个集群网络中存在拥塞的估计。具体来说，我们考虑了四个不同的状态：
1. 很少或没有拥塞
2. 随着队列的填充而增加拥塞
3. 高拥塞
4. 随着队列的耗尽而减少拥塞
这些状态是通过观察延迟以及集群中最近处理过的数据包的丢弃率来估计的。通过将网络分解为这四种粗糙的状态，LSTM能够有效地学习这些机制上的模式，每个机制都有不同的行为。此特性将被添加到之前的[表](week14.md#可伸缩特性表)中的其他特性中。

## 反馈模型
虽然上述（内部）模型可以对集群的队列、路由器和内部流量的行为进行建模，但仍然需要对外部流量的完整跟踪才能生成准确的结果。  
在[流量交互图](week14.md#性能分析)的术语中，内部模型烘托（bake）集群内流量的影响，但LSTM对所有外部流量进行训练，而不仅仅是Mimic-Real。  
为了替换剩余的不可观测流量，内部模型增加了一个反馈器（feeder），该反馈器（feeder）的作用是估计Mimic间（inter-Mimic）流量的到达率，并将其注入到内部模型中。由于小规模模拟中不存在Mimic间（inter-Mimic）流量，且随着模拟规模变化这部分流量规模也会变化，这其实是非常有挑战性的。  
Mimic最终使用流级近似技术来预测不同网络规模的imic间流量的数据包到达率：  
- 反馈模型与内部模型并行训练。MimicNet首先来自于所有外部流的小规模模拟特征包的两次到达之间的时间间隔分布，并按照它们的方向（入口/出口）分开。
- 然而，更复杂的反馈器可以在MimicNet中进行训练和参数化。
- 在整个模拟过程中，反馈器将以主机的集群间需求作为参数，计算活动的流级需求的时间序列，并使用派生的分布从该需求中随机抽取数据包。  
  
主要是为了节约成本。至关重要的是，当输入包时，反馈器独立地生成“包”，将它们的原始特征向量传递给内部模型，并立即丢弃任何输出。这意味着内部模型的隐藏状态被更新，就好像数据包被路由一样，而没有实际承担创建、发送或路由它们的成本。
## 调优（Tuning）和最终模拟
MimicNet将Mimic们组成了一个并行的大规模数据中心模拟。除了考虑到尺度独立性（就是与规模无关性，即保证可伸缩性）的内部模型和反馈器模型之外，它还确保了模型在超参数调优阶段的缩放中存活下来。  
### Mimics组成
一个𝑁-集群MimicNet模拟由单个真实集群、𝑁−1个**Mimic集群**和成比例的核心交换机组成。真实集群继续使用[小规模模拟观察](week14.md#小规模观测)的用户实现。（用户当然可以使用其他检测工具比如dump pcap以及队列深度）。
Mimic集群是通过采用前几节中开发的进出内部模型和反馈器，并将它们封装在thin shim layer（一种兼容层，可以用于在不同于它们开发的软件平台上运行程序，也可用于重定向）中，该层拦截到达集群边界的数据包，定期从反馈器中获取数据包，并使用两者查询内部模型，以预测网络的影响。因此，thin shim的输出要么是一个包，包含它的出口时间和出口位置，要么就是没有包（absent）。  
除了集群的数量外，所有其他参数从小规模测试到最终的模拟都保持不变，这包括反馈模型和流量模式（traffic pattern），它们采用了一个大小（scale）参数，但固定了其他参数（例如，网络负载和流量大小）。
### 超参数调优（可选）
模拟模型包含了一些用户可选择调整的超参数：WBCE权重w（控制丢包率在损失函数中的占比），[Huber损失](week12.md#huber-loss)中的𝛿，神经网络中的参数（LSTM隐藏层大小，训练的迭代次数epochs以及学习率）等。MimicNet已经内置了一些原则性的优化方法，用户当然也可自定义。对于每个测试参数集，MimicNet训练一组模型并运行验证测试，以评估结果的准确性及其尺度独立性（就是可伸缩性，与数据中心规模大小无关，具体来说，分为2，4，8集群，并使用可自定义的优化方法来比较）。  
全保真度比较结果只收集一次，并对每个参数集的MimicNet结果进行评估，基于用户定义的度量，MimicNet使用[贝叶斯优化（BO）](week14.md#贝叶斯优化)，通过EI的获取函数（预期改进）来选择下一个具有最高“预测不确定性”的参数集。这样，BO就能迅速收敛到最优配置上。
MimicNet本身支持两种指标：
#### 基于MSE的指标
对于1比1的指标，MimicNet提供了一个计算MSE的框架。在比较两个模拟中相同流的[FCT](week14.md#流完成时间flow-completion-timefct)时：  
![image](https://user-images.githubusercontent.com/51207072/230707918-8b752d47-d5bb-4ffa-bc05-d639d236d9ad.png)  
由于MimicNet和全保真网络的流集不一定相同---在有限的运行时间跨度内，稍早/稍晚的流完成可以改变观察到的fct集。为了解释这一点，我们只计算交集上的MSE：  
![image](https://user-images.githubusercontent.com/51207072/230708033-e1239caf-12f8-4574-83a9-0ca2733705eb.png)  
#### 基于Wasserstein的 指标
不幸的是，并不是所有的指标都可以如上所述地构建。MimicNet的超参数调优阶段允许用户通过[Wasserstein指标](week14.md#wasserstein指标)（简称W）来测试分布，例如rtt、fct或吞吐量。该度量量化了将一个分布转换为另一个的最小成本。具体来说，对于一维CDF，指标W1是：  
![image](https://user-images.githubusercontent.com/51207072/230708573-4f17895d-f97d-4634-a927-742d715144a1.png)  
𝑊1值并不是尺度（scale）独立的。其数字越低表示相似性越大。
## 原型实现
我们已经在PyTorch/ATen和OMNeT++模拟套件之上，用C++和Python实现了一个完整的MimicNet工作流的原型。给定一个OMNeT++路由器和主机实现，我们的原型将生成训练数据，训练/超调优一组MimicNet模型，并将生成的模型组合成一个优化的、全规模的模拟。这个功能总共有另外25,000行代码。
### 模拟框架
MimicNet构建在OMNeT++ v4.5和INET v2.4上，带有定制的C++模块，将我们的机器学习模型合并到框架中。为了确保实验是可重复的，所有的随机性，包括生成流量的种子，都是可配置的。它们在变量之间保持一致，并在训练、测试和交叉验证中发生变化。
### 并行执行
MimicNet的一个附带好处是，它显著地减少了在并行执行中对同步的需要。为了利用这一特性，我们使用INET的开源PDES实现并行化最终模拟中的每个集群。
### 机器学习框架
们的LSTM模型使用PyTorch 0.4.1和CUDA 9.2 进行训练。超参数调整是在超选择（hyperopt）的帮助下完成的。在运行时，模拟集群模块接受OMNeT++数据包，提取它们的特性，执行lstm的正向步骤，并根据结果通过ECMP转发数据包。为了提高速度，我们的嵌入式lstm是定制的推理引擎，它利用了来自Torch、cuDNN和ATen库的低级C++和CUDA函数。
## 评估

## 论文创新点概述
1. 提出了一种基于深度学习和流水线技术的数据中心网络性能估计方法MimicNet，具有高效、准确、可扩展等优点；
2. 使用FatTree拓扑结构，对数据中心网络的行为进行建模和仿真；
3. 在数千个服务器的数据中心中，MimicNet相对于常规仿真提供了超过两个数量级的加速，并且即使在这种规模下，MimicNet对尾延迟、吞吐量和RTT的估计与真实结果相差不到5％；
4. MimicNet能够适用于各种复杂协议和真实世界的流量模式，为数据中心网络性能评估提供了新的思路和方法。

## 论文不足之处
1. MimicNet使用的是基于包的仿真方法，没有考虑到整个系统的状态，这可能会导致某些性能指标的估计有一定的误差；
2. MimicNet仅仅考虑了数据中心网络的拓扑结构和流量特征，而没有考虑到其他影响性能的因素，例如系统的负载、硬件配置、软件环境等，这也可能会影响到性能指标的准确性；
3. MimicNet的深度学习模型需要大量的数据进行训练，而这些数据的采集和标注也是一项巨大的工作量，可能会受到数据采集和标注难度大、成本高等因素的限制。

